{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Module 'scipy' has no attribute 'empty'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\aleom\\OneDrive - INSTITUTO TECNOLOGICO AUTONOMO DE MEXICO\\ITAM\\Quinto Semestre\\Aprendizaje de Máquina\\Proyectos\\.venv\\Lib\\site-packages\\scipy\\__init__.py:150\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'empty'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mimportlib\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mpprint\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mglmnet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m glmnet; \n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mglmnetPlot\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m glmnetPlot \n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mglmnetPrint\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m glmnetPrint; \n",
      "File \u001b[1;32mc:\\Users\\aleom\\OneDrive - INSTITUTO TECNOLOGICO AUTONOMO DE MEXICO\\ITAM\\Quinto Semestre\\Aprendizaje de Máquina\\Proyectos\\Sexto\\GLMnet\\GLMnet\\glmnet\\__init__.py:10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mglmnetPlot\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m glmnetPlot \n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mglmnetPrint\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m glmnetPrint\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mglmnetCoef\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m glmnetCoef\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mglmnetPredict\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m glmnetPredict\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcvglmnet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cvglmnet\n",
      "File \u001b[1;32mc:\\Users\\aleom\\OneDrive - INSTITUTO TECNOLOGICO AUTONOMO DE MEXICO\\ITAM\\Quinto Semestre\\Aprendizaje de Máquina\\Proyectos\\Sexto\\GLMnet\\GLMnet\\glmnet\\glmnetCoef.py:72\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m--------------------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m glmnetCoef computes coefficients from a \"glmnet\" object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     68\u001b[0m \n\u001b[0;32m     69\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mglmnetPredict\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m glmnetPredict\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mglmnetCoef\u001b[39m(obj, s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, exact \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m s \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\aleom\\OneDrive - INSTITUTO TECNOLOGICO AUTONOMO DE MEXICO\\ITAM\\Quinto Semestre\\Aprendizaje de Máquina\\Proyectos\\Sexto\\GLMnet\\GLMnet\\glmnet\\glmnetPredict.py:110\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterpolate\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mglmnetPredict\u001b[39m(fit,\\\n\u001b[1;32m--> 110\u001b[0m                   newx \u001b[38;5;241m=\u001b[39m \u001b[43mscipy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m([\u001b[38;5;241m0\u001b[39m]), \\\n\u001b[0;32m    111\u001b[0m                   s \u001b[38;5;241m=\u001b[39m scipy\u001b[38;5;241m.\u001b[39mempty([\u001b[38;5;241m0\u001b[39m]), \\\n\u001b[0;32m    112\u001b[0m                   ptype \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlink\u001b[39m\u001b[38;5;124m'\u001b[39m, \\\n\u001b[0;32m    113\u001b[0m                   exact \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, \\\n\u001b[0;32m    114\u001b[0m                   offset \u001b[38;5;241m=\u001b[39m scipy\u001b[38;5;241m.\u001b[39mempty([\u001b[38;5;241m0\u001b[39m])):\n\u001b[0;32m    116\u001b[0m     typebase \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlink\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoefficients\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnonzero\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    117\u001b[0m     indxtf   \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mstartswith(ptype\u001b[38;5;241m.\u001b[39mlower()) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m typebase]\n",
      "File \u001b[1;32mc:\\Users\\aleom\\OneDrive - INSTITUTO TECNOLOGICO AUTONOMO DE MEXICO\\ITAM\\Quinto Semestre\\Aprendizaje de Máquina\\Proyectos\\.venv\\Lib\\site-packages\\scipy\\__init__.py:152\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m()[name]\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m--> 152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    153\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModule \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscipy\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    154\u001b[0m     )\n",
      "\u001b[1;31mAttributeError\u001b[0m: Module 'scipy' has no attribute 'empty'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "if os.path.exists('./glmnet/GLMnet.so'):\n",
    "    os.remove('./glmnet/GLMnet.so')\n",
    "os.system('gfortran ./glmnet/GLMnet.f -fPIC -fdefault-real-8 -shared -o ./glmnet/GLMnet.so')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import scipy, importlib, pprint, matplotlib.pyplot as plt, warnings\n",
    "from glmnet import glmnet; \n",
    "from glmnetPlot import glmnetPlot \n",
    "from glmnetPrint import glmnetPrint; \n",
    "from glmnetCoef import glmnetCoef; \n",
    "from glmnetPredict import glmnetPredict\n",
    "from cvglmnet import cvglmnet;\n",
    "from cvglmnetCoef import cvglmnetCoef\n",
    "from cvglmnetPlot import cvglmnetPlot;\n",
    "from cvglmnetPredict import cvglmnetPredict\n",
    "\n",
    "from aml_utils import test_case_checker, perform_computation\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Linear regression with various regularizers** The UCI Machine Learning dataset repository hosts a dataset giving features of music, and the location (latitude and longitude) at which that music originate. There are actually two versions of this dataset. Either one is OK, but I think you'll find the one with more independent variables more interesting. In this assignment you will investigate methods to predict music location from the provided features. You should regard latitude and longitude as entirely independent.\n",
    "  * First, build a straightforward linear regression of location (latitude and longitude) against features. What is the R-squared? Plot a graph evaluating each regression.\n",
    "  * Does a Box-Cox transformation improve the regressions? Notice that the dependent variable has some negative values, which Box-Cox doesn't like. You can deal with this by remembering that these are angles, so you get to choose the origin. For the rest of the exercise, use the transformation if it does improve things, otherwise, use the raw data.\n",
    "  * Use glmnet to produce:\n",
    "    * A regression regularized by L2 (a ridge regression). You should estimate the regularization coefficient that produces the minimum error. Is the regularized regression better than the unregularized regression?\n",
    "    * A regression regularized by L1 (a lasso regression). You should estimate the regularization coefficient that produces the minimum error. How many variables are used by this regression? Is the regularized regression better than the unregularized regression?\n",
    "    * A regression regularized by elastic net (equivalently, a regression regularized by a convex combination of L1 and L2 weighted by a parameter `alpha`). Try three values of `alpha`. You should estimate the regularization coefficient `lambda` that produces the minimum error. How many variables are used by this regression? Is the regularized regression better than the unregularized regression?\n",
    "2. **Logistic regression** The UCI Machine Learning dataset repository hosts a dataset giving whether a Taiwanese credit card user defaults against a variety of features here. In this part of the assignment you will use logistic regression to predict whether the user defaults. You should ignore outliers, but you should try the various regularization schemes discussed above.\n",
    "\n",
    "<font color='red'>Attention:</font> After finishing this notebook, you will need to do a follow-up quiz as well. The overall grade for this assignment is based on this notebook and the follow-up quiz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UCI Machine Learning dataset repository hosts a dataset that provides a set of features of music, and the location (latitude and longitude) at which that music originates at https://archive.ics.uci.edu/ml/datasets/Geographical+Original+of+Music. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Input/Output**: This data has 118 columns; the first 116 columns are the music features, and the last two columns are the music origin's latitude and the longitude, respectively.\n",
    "\n",
    "* **Missing Data**: There is no missing data.\n",
    "\n",
    "* **Final Goal**: We want to **properly** fit a linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.161286</td>\n",
       "      <td>7.835325</td>\n",
       "      <td>2.911583</td>\n",
       "      <td>0.984049</td>\n",
       "      <td>-1.499546</td>\n",
       "      <td>-2.094097</td>\n",
       "      <td>0.576000</td>\n",
       "      <td>-1.205671</td>\n",
       "      <td>1.849122</td>\n",
       "      <td>-0.425598</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.364194</td>\n",
       "      <td>-0.364194</td>\n",
       "      <td>-0.364194</td>\n",
       "      <td>-0.364194</td>\n",
       "      <td>-0.364194</td>\n",
       "      <td>-0.364194</td>\n",
       "      <td>-0.364194</td>\n",
       "      <td>-0.364194</td>\n",
       "      <td>-15.75</td>\n",
       "      <td>-47.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.225763</td>\n",
       "      <td>-0.094169</td>\n",
       "      <td>-0.603646</td>\n",
       "      <td>0.497745</td>\n",
       "      <td>0.874036</td>\n",
       "      <td>0.290280</td>\n",
       "      <td>-0.077659</td>\n",
       "      <td>-0.887385</td>\n",
       "      <td>0.432062</td>\n",
       "      <td>-0.093963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.936616</td>\n",
       "      <td>0.936616</td>\n",
       "      <td>0.936616</td>\n",
       "      <td>0.936616</td>\n",
       "      <td>0.936616</td>\n",
       "      <td>0.936616</td>\n",
       "      <td>0.936616</td>\n",
       "      <td>0.936616</td>\n",
       "      <td>14.91</td>\n",
       "      <td>-23.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.692525</td>\n",
       "      <td>-0.517801</td>\n",
       "      <td>-0.788035</td>\n",
       "      <td>1.214351</td>\n",
       "      <td>-0.907214</td>\n",
       "      <td>0.880213</td>\n",
       "      <td>0.406899</td>\n",
       "      <td>-0.694895</td>\n",
       "      <td>-0.901869</td>\n",
       "      <td>-1.701574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.603755</td>\n",
       "      <td>0.603755</td>\n",
       "      <td>0.603755</td>\n",
       "      <td>0.603755</td>\n",
       "      <td>0.603755</td>\n",
       "      <td>0.603755</td>\n",
       "      <td>0.603755</td>\n",
       "      <td>0.603755</td>\n",
       "      <td>12.65</td>\n",
       "      <td>-8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.735562</td>\n",
       "      <td>-0.684055</td>\n",
       "      <td>2.058215</td>\n",
       "      <td>0.716328</td>\n",
       "      <td>-0.011393</td>\n",
       "      <td>0.805396</td>\n",
       "      <td>1.497982</td>\n",
       "      <td>0.114752</td>\n",
       "      <td>0.692847</td>\n",
       "      <td>0.052377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.187169</td>\n",
       "      <td>0.187169</td>\n",
       "      <td>0.187169</td>\n",
       "      <td>0.187169</td>\n",
       "      <td>0.187169</td>\n",
       "      <td>0.187169</td>\n",
       "      <td>0.187169</td>\n",
       "      <td>0.187169</td>\n",
       "      <td>9.03</td>\n",
       "      <td>38.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.570272</td>\n",
       "      <td>0.273157</td>\n",
       "      <td>-0.279214</td>\n",
       "      <td>0.083456</td>\n",
       "      <td>1.049331</td>\n",
       "      <td>-0.869295</td>\n",
       "      <td>-0.265858</td>\n",
       "      <td>-0.401676</td>\n",
       "      <td>-0.872639</td>\n",
       "      <td>1.147483</td>\n",
       "      <td>...</td>\n",
       "      <td>1.620715</td>\n",
       "      <td>1.620715</td>\n",
       "      <td>1.620715</td>\n",
       "      <td>1.620715</td>\n",
       "      <td>1.620715</td>\n",
       "      <td>1.620715</td>\n",
       "      <td>1.620715</td>\n",
       "      <td>1.620715</td>\n",
       "      <td>34.03</td>\n",
       "      <td>-6.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>0.399577</td>\n",
       "      <td>0.310805</td>\n",
       "      <td>-0.039326</td>\n",
       "      <td>-0.111546</td>\n",
       "      <td>0.304586</td>\n",
       "      <td>-0.943453</td>\n",
       "      <td>0.114960</td>\n",
       "      <td>-0.335898</td>\n",
       "      <td>0.826753</td>\n",
       "      <td>-0.393786</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.415247</td>\n",
       "      <td>-0.415247</td>\n",
       "      <td>-0.415247</td>\n",
       "      <td>-0.415247</td>\n",
       "      <td>-0.415247</td>\n",
       "      <td>-0.415247</td>\n",
       "      <td>-0.415247</td>\n",
       "      <td>-0.415247</td>\n",
       "      <td>-6.17</td>\n",
       "      <td>35.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>1.640386</td>\n",
       "      <td>1.306224</td>\n",
       "      <td>0.192745</td>\n",
       "      <td>-1.816855</td>\n",
       "      <td>-1.311906</td>\n",
       "      <td>-2.128963</td>\n",
       "      <td>-1.875967</td>\n",
       "      <td>0.094232</td>\n",
       "      <td>-1.429742</td>\n",
       "      <td>0.873777</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.817538</td>\n",
       "      <td>-0.817538</td>\n",
       "      <td>-0.817538</td>\n",
       "      <td>-0.817538</td>\n",
       "      <td>-0.817538</td>\n",
       "      <td>-0.817538</td>\n",
       "      <td>-0.817538</td>\n",
       "      <td>-0.817538</td>\n",
       "      <td>11.55</td>\n",
       "      <td>104.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>-0.772360</td>\n",
       "      <td>-0.670596</td>\n",
       "      <td>-0.840420</td>\n",
       "      <td>-0.832105</td>\n",
       "      <td>0.277346</td>\n",
       "      <td>1.152162</td>\n",
       "      <td>0.241470</td>\n",
       "      <td>0.229092</td>\n",
       "      <td>0.019036</td>\n",
       "      <td>-0.068804</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.515309</td>\n",
       "      <td>-0.515309</td>\n",
       "      <td>-0.515309</td>\n",
       "      <td>-0.515309</td>\n",
       "      <td>-0.515309</td>\n",
       "      <td>-0.515309</td>\n",
       "      <td>-0.515309</td>\n",
       "      <td>-0.515309</td>\n",
       "      <td>41.33</td>\n",
       "      <td>19.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>-0.996965</td>\n",
       "      <td>-1.099395</td>\n",
       "      <td>3.515274</td>\n",
       "      <td>-0.508185</td>\n",
       "      <td>-1.102654</td>\n",
       "      <td>0.192081</td>\n",
       "      <td>0.069821</td>\n",
       "      <td>0.264674</td>\n",
       "      <td>-0.411533</td>\n",
       "      <td>0.501164</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074855</td>\n",
       "      <td>0.074855</td>\n",
       "      <td>0.074855</td>\n",
       "      <td>0.074855</td>\n",
       "      <td>0.074855</td>\n",
       "      <td>0.074855</td>\n",
       "      <td>0.074855</td>\n",
       "      <td>0.074855</td>\n",
       "      <td>54.68</td>\n",
       "      <td>25.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058</th>\n",
       "      <td>-0.150911</td>\n",
       "      <td>-0.094333</td>\n",
       "      <td>-0.568885</td>\n",
       "      <td>-0.614652</td>\n",
       "      <td>0.332477</td>\n",
       "      <td>-0.954948</td>\n",
       "      <td>-1.527722</td>\n",
       "      <td>-1.591471</td>\n",
       "      <td>-3.678713</td>\n",
       "      <td>-5.930209</td>\n",
       "      <td>...</td>\n",
       "      <td>5.835585</td>\n",
       "      <td>5.835585</td>\n",
       "      <td>5.835585</td>\n",
       "      <td>5.835585</td>\n",
       "      <td>5.835585</td>\n",
       "      <td>5.835585</td>\n",
       "      <td>5.835585</td>\n",
       "      <td>5.835585</td>\n",
       "      <td>54.68</td>\n",
       "      <td>25.31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1059 rows × 118 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6    \\\n",
       "0     7.161286  7.835325  2.911583  0.984049 -1.499546 -2.094097  0.576000   \n",
       "1     0.225763 -0.094169 -0.603646  0.497745  0.874036  0.290280 -0.077659   \n",
       "2    -0.692525 -0.517801 -0.788035  1.214351 -0.907214  0.880213  0.406899   \n",
       "3    -0.735562 -0.684055  2.058215  0.716328 -0.011393  0.805396  1.497982   \n",
       "4     0.570272  0.273157 -0.279214  0.083456  1.049331 -0.869295 -0.265858   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1054  0.399577  0.310805 -0.039326 -0.111546  0.304586 -0.943453  0.114960   \n",
       "1055  1.640386  1.306224  0.192745 -1.816855 -1.311906 -2.128963 -1.875967   \n",
       "1056 -0.772360 -0.670596 -0.840420 -0.832105  0.277346  1.152162  0.241470   \n",
       "1057 -0.996965 -1.099395  3.515274 -0.508185 -1.102654  0.192081  0.069821   \n",
       "1058 -0.150911 -0.094333 -0.568885 -0.614652  0.332477 -0.954948 -1.527722   \n",
       "\n",
       "           7         8         9    ...       108       109       110  \\\n",
       "0    -1.205671  1.849122 -0.425598  ... -0.364194 -0.364194 -0.364194   \n",
       "1    -0.887385  0.432062 -0.093963  ...  0.936616  0.936616  0.936616   \n",
       "2    -0.694895 -0.901869 -1.701574  ...  0.603755  0.603755  0.603755   \n",
       "3     0.114752  0.692847  0.052377  ...  0.187169  0.187169  0.187169   \n",
       "4    -0.401676 -0.872639  1.147483  ...  1.620715  1.620715  1.620715   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1054 -0.335898  0.826753 -0.393786  ... -0.415247 -0.415247 -0.415247   \n",
       "1055  0.094232 -1.429742  0.873777  ... -0.817538 -0.817538 -0.817538   \n",
       "1056  0.229092  0.019036 -0.068804  ... -0.515309 -0.515309 -0.515309   \n",
       "1057  0.264674 -0.411533  0.501164  ...  0.074855  0.074855  0.074855   \n",
       "1058 -1.591471 -3.678713 -5.930209  ...  5.835585  5.835585  5.835585   \n",
       "\n",
       "           111       112       113       114       115    116     117  \n",
       "0    -0.364194 -0.364194 -0.364194 -0.364194 -0.364194 -15.75  -47.95  \n",
       "1     0.936616  0.936616  0.936616  0.936616  0.936616  14.91  -23.51  \n",
       "2     0.603755  0.603755  0.603755  0.603755  0.603755  12.65   -8.00  \n",
       "3     0.187169  0.187169  0.187169  0.187169  0.187169   9.03   38.74  \n",
       "4     1.620715  1.620715  1.620715  1.620715  1.620715  34.03   -6.85  \n",
       "...        ...       ...       ...       ...       ...    ...     ...  \n",
       "1054 -0.415247 -0.415247 -0.415247 -0.415247 -0.415247  -6.17   35.74  \n",
       "1055 -0.817538 -0.817538 -0.817538 -0.817538 -0.817538  11.55  104.91  \n",
       "1056 -0.515309 -0.515309 -0.515309 -0.515309 -0.515309  41.33   19.80  \n",
       "1057  0.074855  0.074855  0.074855  0.074855  0.074855  54.68   25.31  \n",
       "1058  5.835585  5.835585  5.835585  5.835585  5.835585  54.68   25.31  \n",
       "\n",
       "[1059 rows x 118 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('music/default_plus_chromatic_features_1059_tracks.txt', header=None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1059, 116), (1059,), (1059,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_full = df.iloc[:,:-2].values\n",
    "lat_full = df.iloc[:,-2].values\n",
    "lon_full = df.iloc[:,-1].values\n",
    "X_full.shape, lat_full.shape, lon_full.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making the Dependent Variables Positive\n",
    "\n",
    "This will make the data compatible with the box-cox transformation that we will later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_full = 90 + lat_full\n",
    "lon_full = 180 + lon_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_detector = 'LOF'\n",
    "\n",
    "if outlier_detector == 'LOF':\n",
    "    outlier_clf = LocalOutlierFactor(novelty=False)\n",
    "elif outlier_detector == 'IF':\n",
    "    outlier_clf = IsolationForest(warm_start=True, random_state=12345)\n",
    "elif outlier_detector == 'EE':\n",
    "    outlier_clf = EllipticEnvelope(random_state=12345)\n",
    "else:\n",
    "    outlier_clf = None\n",
    "\n",
    "is_not_outlier = outlier_clf.fit_predict(X_full) if outlier_clf is not None else np.ones_like(lat_full)>0\n",
    "X_useful = X_full[is_not_outlier==1,:]\n",
    "lat_useful = lat_full[is_not_outlier==1]\n",
    "lon_useful = lon_full[is_not_outlier==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Suggestion**: You may find it instructive to explore the effect of the different outlier detection methods on the accuracy of the linear regression model. \n",
    "\n",
    "There is a brief introduction about each of the implemented OD methods along with some nice visualizations at https://scikit-learn.org/stable/modules/outlier_detection.html ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Train-Validation-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_indices, test_indices = train_test_split(np.arange(X_useful.shape[0]), test_size=0.2, random_state=12345)\n",
    "\n",
    "X_train_val = X_useful[train_val_indices, :]\n",
    "lat_train_val = lat_useful[train_val_indices]\n",
    "lon_train_val = lon_useful[train_val_indices]\n",
    "\n",
    "X_test = X_useful[test_indices, :]\n",
    "lat_test = lat_useful[test_indices]\n",
    "lon_test = lon_useful[test_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Building a Simple Linear Regression Model (Scikit-Learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'perform_computation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearRegression\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mperform_computation\u001b[49m:\n\u001b[0;32m      4\u001b[0m     X, Y \u001b[38;5;241m=\u001b[39m X_train_val, lat_train_val\n\u001b[0;32m      5\u001b[0m     reg_lat \u001b[38;5;241m=\u001b[39m LinearRegression()\u001b[38;5;241m.\u001b[39mfit(X, Y)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'perform_computation' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "if perform_computation:\n",
    "    X, Y = X_train_val, lat_train_val\n",
    "    reg_lat = LinearRegression().fit(X, Y)\n",
    "    train_r2_lat = reg_lat.score(X,Y)\n",
    "    fitted_lat = reg_lat.predict(X)\n",
    "    residuals_lat = Y-fitted_lat\n",
    "    train_mse_lat = (residuals_lat**2).mean()\n",
    "    test_mse_lat = np.mean((reg_lat.predict(X_test)-lat_test)**2)\n",
    "    test_r2_lat = reg_lat.score(X_test,lat_test)\n",
    "\n",
    "    X, Y = X_train_val, lon_train_val\n",
    "    reg_lon = LinearRegression().fit(X, Y)\n",
    "    train_r2_lon = reg_lon.score(X,Y)\n",
    "    fitted_lon = reg_lon.predict(X)\n",
    "    residuals_lon = Y-fitted_lon\n",
    "    train_mse_lon = (residuals_lon**2).mean()\n",
    "    test_mse_lon = np.mean((reg_lon.predict(X_test)-lon_test)**2)\n",
    "    test_r2_lon = reg_lon.score(X_test,lon_test)\n",
    "\n",
    "    fig, axes = plt.subplots(1,2, figsize=(10,6.), dpi=100)\n",
    "\n",
    "    ax = axes[0]\n",
    "    ax.scatter(fitted_lat, residuals_lat)\n",
    "    ax.set_xlabel('Fitted Latitude')\n",
    "    ax.set_ylabel('Latitude Residuals')\n",
    "    _ = ax.set_title(f'Residuals Vs. Fitted Latitude.\\n' +\n",
    "                     f'Training R2=%.3f, Testing R2=%.3f\\n' % (train_r2_lat, test_r2_lat) +\n",
    "                     f'Training MSE=%.3f, Testing MSE=%.3f' % (train_mse_lat, test_mse_lat))\n",
    "\n",
    "    ax = axes[1]\n",
    "    ax.scatter(fitted_lon, residuals_lon)\n",
    "    ax.set_xlabel('Fitted Longitude')\n",
    "    ax.set_ylabel('Longitude Residuals')\n",
    "    _ = ax.set_title(f'Residuals Vs. Fitted Longitude.\\n' +\n",
    "                     f'Training R2=%.3f, Testing R2=%.3f\\n' % (train_r2_lon, test_r2_lon) +\n",
    "                     f'Training MSE=%.3f, Testing MSE=%.3f' % (train_mse_lon, test_mse_lon))\n",
    "    fig.set_tight_layout([0, 0, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Building a Simple Linear Regression (glmnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Task 1</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function `glmnet_vanilla` that fits a linear regression model from the glmnet library, and takes the following arguments as input:\n",
    "\n",
    "1. `X_train`: A numpy array of the shape `(N,d)` where `N` is the number of training data points, and `d` is the data dimension. Do not assume anything about `N` or `d` other than being a positive integer.\n",
    "2. `Y_train`: A numpy array of the shape `(N,)` where `N` is the number of training data points.\n",
    "3. `X_test`: A numpy array of the shape `(N_test,d)` where `N_test` is the number of testing data points, and `d` is the data dimension.\n",
    "\n",
    "Your model should train on the training features and labels, and then predict on the test data. Your model should return the following two items:\n",
    "\n",
    "1. `fitted_Y`: The predicted values on the test data as a numpy array with a shape of `(N_test,)` where `N_test` is the number of testing data points.\n",
    "\n",
    "2. `glmnet_model`: The glmnet library's returned model stored as a python dictionary.\n",
    "\n",
    "**Important Notes**:\n",
    "1. **Do not** play with the default options unless you're instructed to.\n",
    "2. You may find this glmnet documentation helpful: https://github.com/bbalasub1/glmnet_python/blob/master/test/glmnet_examples.ipynb\n",
    "    * You may find it useful to read about the gaussian family in the first section, the functions `glmnet` and `glmnetPredict`, and their arguments.\n",
    "3. **Do not** perform any cross-validation for this task.\n",
    "4. **Do not** play with the regularization settings in the **training call**.\n",
    "5. **For prediction** on the test data, make sure that a **regularization coefficient of 0** was used. \n",
    "6. You may need to choose the proper `family` variable when you're training the model.\n",
    "7. You may need to choose the proper `ptype` variable when you're predicting on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2c9eb89fd8a59964aca8f20787293b07",
     "grade": false,
     "grade_id": "cell-6785a420e10621a4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def glmnet_vanilla(X_train, Y_train, X_test=None):\n",
    "    if X_test is None:\n",
    "        X_test = X_train.copy().astype(np.float64)\n",
    "    # Creating Scratch Variables For glmnet Consumption\n",
    "    X_train = X_train.copy().astype(np.float64)\n",
    "    Y_train = Y_train.copy().astype(np.float64)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    glmnet_model = glmnet(x=X_train, y=Y_train, family=\"gaussian\")\n",
    "    fitted_Y = glmnetPredict(glmnet_model, newx=X_test, s=np.array([0]), ptype=\"link\").flatten()\n",
    "\n",
    "    assert fitted_Y.shape == (X_test.shape[0],), 'fitted_Y should not be two dimensional (hint: reshaping may be helpful)'\n",
    "    assert isinstance(glmnet_model, dict)\n",
    "    assert list(glmnet_model.keys()) == ['a0','beta','dev','nulldev','df','lambdau','npasses','jerr','dim','offset','class']\n",
    "    return fitted_Y, glmnet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "86762e1e2651868289da6cf62186b32c",
     "grade": true,
     "grade_id": "cell-d5a4943d1ed88252",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'glmnet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m some_X \u001b[38;5;241m=\u001b[39m (np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m35\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m5\u001b[39m) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m13\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[0;32m      2\u001b[0m some_Y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(some_X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m some_pred, some_model \u001b[38;5;241m=\u001b[39m \u001b[43mglmnet_vanilla\u001b[49m\u001b[43m(\u001b[49m\u001b[43msome_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msome_Y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(some_pred\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m3\u001b[39m), np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m20.352\u001b[39m, \u001b[38;5;241m44.312\u001b[39m, \u001b[38;5;241m39.637\u001b[39m, \u001b[38;5;241m74.146\u001b[39m, \u001b[38;5;241m20.352\u001b[39m, \u001b[38;5;241m49.605\u001b[39m, \u001b[38;5;241m24.596\u001b[39m]))\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Checking against the pre-computed test database\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[44], line 9\u001b[0m, in \u001b[0;36mglmnet_vanilla\u001b[1;34m(X_train, Y_train, X_test)\u001b[0m\n\u001b[0;32m      6\u001b[0m Y_train \u001b[38;5;241m=\u001b[39m Y_train\u001b[38;5;241m.\u001b[39mcopy()\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# YOUR CODE HERE\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m glmnet_model \u001b[38;5;241m=\u001b[39m \u001b[43mglmnet\u001b[49m(x\u001b[38;5;241m=\u001b[39mX_train, y\u001b[38;5;241m=\u001b[39mY_train, family\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgaussian\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m fitted_Y \u001b[38;5;241m=\u001b[39m glmnetPredict(glmnet_model, newx\u001b[38;5;241m=\u001b[39mX_test, s\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m]), ptype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlink\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m fitted_Y\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m (X_test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfitted_Y should not be two dimensional (hint: reshaping may be helpful)\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'glmnet' is not defined"
     ]
    }
   ],
   "source": [
    "some_X = (np.arange(35).reshape(7,5) ** 13) % 20\n",
    "some_Y = np.sum(some_X, axis=1)\n",
    "some_pred, some_model = glmnet_vanilla(some_X, some_Y)\n",
    "assert np.array_equal(some_pred.round(3), np.array([20.352, 44.312, 39.637, 74.146, 20.352, 49.605, 24.596]))\n",
    "\n",
    "# Checking against the pre-computed test database\n",
    "test_results = test_case_checker(lambda *args,**kwargs: glmnet_vanilla(*args,**kwargs)[0], task_id=1)\n",
    "assert test_results['passed'], test_results['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_plot(trainer):\n",
    "    # Latitude Training, Prediction, Evaluation, etc.\n",
    "    lat_pred_train = trainer(X_train_val, lat_train_val, X_train_val)[0]\n",
    "    train_r2_lat = r2_score(lat_train_val, lat_pred_train)\n",
    "    residuals_lat = lat_train_val - lat_pred_train\n",
    "    train_mse_lat = (residuals_lat**2).mean()\n",
    "    lat_pred_test = trainer(X_train_val, lat_train_val, X_test)[0]\n",
    "    test_mse_lat = np.mean((lat_pred_test-lat_test)**2)\n",
    "    test_r2_lat = r2_score(lat_test, lat_pred_test)\n",
    "\n",
    "    # Longitude Training, Prediction, Evaluation, etc.\n",
    "    lon_pred_train = trainer(X_train_val, lon_train_val, X_train_val)[0]\n",
    "    train_r2_lon = r2_score(lon_train_val, lon_pred_train)\n",
    "    residuals_lon = lon_train_val - lon_pred_train\n",
    "    train_mse_lon = (residuals_lon**2).mean()\n",
    "    lon_pred_test = trainer(X_train_val, lon_train_val, X_test)[0]\n",
    "    test_mse_lon = np.mean((lon_pred_test-lon_test)**2)\n",
    "    test_r2_lon = r2_score(lon_test, lon_pred_test)\n",
    "\n",
    "    fig, axes = plt.subplots(1,2, figsize=(10,6.), dpi=100)\n",
    "\n",
    "    ax = axes[0]\n",
    "    ax.scatter(lat_pred_train, residuals_lat)\n",
    "    ax.set_xlabel('Fitted Latitude')\n",
    "    ax.set_ylabel('Latitude Residuals')\n",
    "    _ = ax.set_title(f'Residuals Vs. Fitted Latitude.\\n' +\n",
    "                     f'Training R2=%.3f, Testing R2=%.3f\\n' % (train_r2_lat, test_r2_lat) +\n",
    "                     f'Training MSE=%.3f, Testing MSE=%.3f' % (train_mse_lat, test_mse_lat))\n",
    "\n",
    "    ax = axes[1]\n",
    "    ax.scatter(lon_pred_train, residuals_lon)\n",
    "    ax.set_xlabel('Fitted Longitude')\n",
    "    ax.set_ylabel('Longitude Residuals')\n",
    "    _ = ax.set_title(f'Residuals Vs. Fitted Longitude.\\n' +\n",
    "                     f'Training R2=%.3f, Testing R2=%.3f\\n' % (train_r2_lon, test_r2_lon) +\n",
    "                     f'Training MSE=%.3f, Testing MSE=%.3f' % (train_mse_lon, test_mse_lon))\n",
    "    fig.set_tight_layout([0, 0, 1, 1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'perform_computation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mperform_computation\u001b[49m:\n\u001b[0;32m      2\u001b[0m     train_and_plot(glmnet_vanilla)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'perform_computation' is not defined"
     ]
    }
   ],
   "source": [
    "if perform_computation:\n",
    "    train_and_plot(glmnet_vanilla)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Box-Cox Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Task 2</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function `boxcox_lambda` that takes a numpy array `y` as input, and produce the best box-cox transformation $\\lambda$ parameter `best_lam` as a scalar. \n",
    "\n",
    "**Hint**: Do not implement this function yourself. You may find some useful function here https://docs.scipy.org/doc/scipy/reference/stats.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fd7a7e0db2b3d850c189de6027e9085f",
     "grade": false,
     "grade_id": "cell-b890cc74d0a27f33",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def boxcox_lambda(y):\n",
    "    assert y.ndim==1\n",
    "    assert (y>0).all()\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    _, best_lam = boxcox(y)\n",
    "\n",
    "    return best_lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "23724e1e8146373413fefd96b6f537ad",
     "grade": true,
     "grade_id": "cell-2040f71f314d3598",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'boxcox' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m some_X \u001b[38;5;241m=\u001b[39m (np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m35\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m5\u001b[39m) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m13\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[0;32m      2\u001b[0m some_Y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(some_X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[43mboxcox_lambda\u001b[49m\u001b[43m(\u001b[49m\u001b[43msome_Y\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m3\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.216\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Checking against the pre-computed test database\u001b[39;00m\n\u001b[0;32m      6\u001b[0m test_results \u001b[38;5;241m=\u001b[39m test_case_checker(boxcox_lambda, task_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "Cell \u001b[1;32mIn[22], line 6\u001b[0m, in \u001b[0;36mboxcox_lambda\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (y\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mall()\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# YOUR CODE HERE\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m _, best_lam \u001b[38;5;241m=\u001b[39m \u001b[43mboxcox\u001b[49m(y)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m best_lam\n",
      "\u001b[1;31mNameError\u001b[0m: name 'boxcox' is not defined"
     ]
    }
   ],
   "source": [
    "some_X = (np.arange(35).reshape(7,5) ** 13) % 20\n",
    "some_Y = np.sum(some_X, axis=1)\n",
    "assert boxcox_lambda(some_Y).round(3) == -0.216\n",
    "\n",
    "# Checking against the pre-computed test database\n",
    "test_results = test_case_checker(boxcox_lambda, task_id=2)\n",
    "assert test_results['passed'], test_results['message']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Task 3</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function `boxcox_transform` that takes a numpy array `y` and the box-cox transformation $\\lambda$ parameter `lam` as input, and returns the numpy array `transformed_y` which is the box-cox transformation of `y` using $\\lambda$. \n",
    "\n",
    "**Hint**: Do not implement this function yourself. You may find some useful function here https://docs.scipy.org/doc/scipy/reference/stats.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1423295e95b9198d1a90c8cc70c45a7c",
     "grade": false,
     "grade_id": "cell-362af67d00cb7923",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def boxcox_transform(y, lam):\n",
    "    assert y.ndim==1\n",
    "    assert (y>0).all()\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    if lam == 0:\n",
    "        transformed_y = np.log(y)\n",
    "    else:\n",
    "        transformed_y = (y**lam - 1) / lam\n",
    "  \n",
    "    return transformed_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eda10bcc2f0a61348e18cf10f2f6b87b",
     "grade": true,
     "grade_id": "cell-b8bffc82a9388e13",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_case_checker' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(boxcox_transform(some_Y, lam\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m3\u001b[39m), np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m2.996\u001b[39m, \u001b[38;5;241m3.807\u001b[39m, \u001b[38;5;241m3.689\u001b[39m, \u001b[38;5;241m4.317\u001b[39m, \u001b[38;5;241m2.996\u001b[39m, \u001b[38;5;241m3.892\u001b[39m, \u001b[38;5;241m3.178\u001b[39m]))\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Checking against the pre-computed test database\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m test_results \u001b[38;5;241m=\u001b[39m \u001b[43mtest_case_checker\u001b[49m(boxcox_transform, task_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m test_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpassed\u001b[39m\u001b[38;5;124m'\u001b[39m], test_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_case_checker' is not defined"
     ]
    }
   ],
   "source": [
    "some_X = (np.arange(35).reshape(7,5) ** 13) % 20\n",
    "some_Y = np.sum(some_X, axis=1)\n",
    "assert np.array_equal(boxcox_transform(some_Y, lam=0).round(3), np.array([2.996, 3.807, 3.689, 4.317, 2.996, 3.892, 3.178]))\n",
    "\n",
    "# Checking against the pre-computed test database\n",
    "test_results = test_case_checker(boxcox_transform, task_id=3)\n",
    "assert test_results['passed'], test_results['message']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Task 4</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function `boxcox_inv_transform` that takes a numpy array `transformed_y` and the box-cox transformation $\\lambda$ parameter `lam` as input, and returns the numpy array `y` which is the inverse box-cox transformation of `transformed_y` using $\\lambda$. \n",
    "\n",
    "1. If $\\lambda \\neq 0$: \n",
    "$$y = |y^{bc}\\cdot \\lambda + 1|^{\\frac{1}{\\lambda}}$$\n",
    "2. If $\\lambda = 0$:\n",
    "$$y = e^{y^{bc}}$$\n",
    "\n",
    "**Hint**: You need to implement this function yourself!\n",
    "\n",
    "**Important Note**: Be very careful about the signs, absolute values, and raising to exponents with decimal points. For something to be raised to any power that is not a full integer, you need to make sure that the base is positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1993169132bc4d8826c218b2806592b2",
     "grade": false,
     "grade_id": "cell-bb2e3b433c1b0e67",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def boxcox_inv_transform(transformed_y, lam):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    if lam == 0:\n",
    "        y = np.exp(transformed_y)\n",
    "    else:\n",
    "        y = np.abs(transformed_y * lam + 1) ** (1 / lam)\n",
    "    \n",
    "    assert not np.isnan(y).any()\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "27e39ee472f7b157ecaa529ff3bc2a56",
     "grade": true,
     "grade_id": "cell-40dd0d43a2d5aef6",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_case_checker' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(iden, some_Y\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m3\u001b[39m))\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Checking against the pre-computed test database\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m test_results \u001b[38;5;241m=\u001b[39m \u001b[43mtest_case_checker\u001b[49m(boxcox_inv_transform, task_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m test_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpassed\u001b[39m\u001b[38;5;124m'\u001b[39m], test_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_case_checker' is not defined"
     ]
    }
   ],
   "source": [
    "some_X = (np.arange(35).reshape(7,5) ** 13) % 20\n",
    "some_Y = np.sum(some_X, axis=1)/10\n",
    "some_invbc = boxcox_inv_transform(some_Y, lam=0).round(3)\n",
    "assert np.array_equal(some_invbc, np.array([7.389, 90.017, 54.598, 1808.042, 7.389,  134.29 ,11.023]))\n",
    "\n",
    "another_invbc = boxcox_inv_transform(some_Y, lam=5).round(3)\n",
    "assert np.array_equal(another_invbc, np.array([1.615, 1.88 , 1.838, 2.075, 1.615, 1.911, 1.67 ]))\n",
    "\n",
    "iden = boxcox_inv_transform(boxcox_transform(some_Y, lam=5), lam=5).round(3)\n",
    "assert np.array_equal(iden, some_Y.round(3))\n",
    "\n",
    "# Checking against the pre-computed test database\n",
    "test_results = test_case_checker(boxcox_inv_transform, task_id=4)\n",
    "assert test_results['passed'], test_results['message']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Task 5</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the box-cox functions you previously wrote, write a function `glmnet_bc` that fits a linear regression model from the glmnet library with the box-cox transformation applied on the labels, and takes the following arguments as input:\n",
    "\n",
    "1. `X_train`: A numpy array of the shape `(N,d)` where `N` is the number of training data points, and `d` is the data dimension. Do not assume anything about `N` or `d` other than being a positive integer.\n",
    "2. `Y_train`: A numpy array of the shape `(N,)` where `N` is the number of training data points.\n",
    "3. `X_test`: A numpy array of the shape `(N_test,d)` where `N_test` is the number of testing data points, and `d` is the data dimension.\n",
    "\n",
    "Your model should train on the training features and labels, and then predict on the test data. Your model should return the following two items:\n",
    "\n",
    "1. `fitted_test`: The predicted values on the test data as a numpy array with a shape of `(N_test,)` where `N_test` is the number of testing data points.\n",
    "\n",
    "2. `glmnet_model`: The glmnet library's returned model stored as a python dictionary.\n",
    "\n",
    "You should first obtain the best box-cox lambda parameter from the training data. Then transform the training labels before passing them to the training procedure. This will cause the trained model to be operating on the box-cox transformed space. Therefore, the test predictions should be box-cox inverse transformed before reporting them as output. \n",
    "\n",
    "Use the `glmnet_vanilla` function you already written on the box-cox transformed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b66220358671047bf6c6fb6c2a622f83",
     "grade": false,
     "grade_id": "cell-885112d310d72cd8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def glmnet_bc(X_train, Y_train, X_test=None):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    best_lam = boxcox_lambda(Y_train)\n",
    "    Y_train_bc = boxcox_transform(Y_train, best_lam)\n",
    "    glmnet_model = glmnet(x=X_train, y=Y_train_bc, family=\"gaussian\")\n",
    "    \n",
    "    if X_test is not None:\n",
    "        Y_test_bc = glmnetPredict(glmnet_model, newx=X_test, s=np.array([0]), ptype=\"link\").flatten()\n",
    "\n",
    "        fitted_test = boxcox_inv_transform(Y_test_bc, best_lam)\n",
    "    else:\n",
    "        fitted_test = None\n",
    "\n",
    "    glmnet_model = dict(glmnet_model)\n",
    "    \n",
    "    assert isinstance(glmnet_model, dict)\n",
    "    return fitted_test, glmnet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ea89e41ec0a83cfa6a7f8729dc80bc57",
     "grade": true,
     "grade_id": "cell-f2455339942351cd",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'boxcox' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m some_X \u001b[38;5;241m=\u001b[39m (np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m35\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m5\u001b[39m) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m13\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[0;32m      2\u001b[0m some_Y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(some_X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m some_pred, some_model \u001b[38;5;241m=\u001b[39m \u001b[43mglmnet_bc\u001b[49m\u001b[43m(\u001b[49m\u001b[43msome_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msome_Y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(some_pred\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m3\u001b[39m), np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m20.012\u001b[39m, \u001b[38;5;241m42.985\u001b[39m, \u001b[38;5;241m40.189\u001b[39m, \u001b[38;5;241m75.252\u001b[39m, \u001b[38;5;241m20.012\u001b[39m, \u001b[38;5;241m50.095\u001b[39m, \u001b[38;5;241m24.32\u001b[39m ]))\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Checking against the pre-computed test database\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[28], line 4\u001b[0m, in \u001b[0;36mglmnet_bc\u001b[1;34m(X_train, Y_train, X_test)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mglmnet_bc\u001b[39m(X_train, Y_train, X_test\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m      2\u001b[0m     \n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# YOUR CODE HERE\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m     best_lam \u001b[38;5;241m=\u001b[39m \u001b[43mboxcox_lambda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Step 2: Transform the training labels using the Box-Cox transformation\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     Y_train_bc \u001b[38;5;241m=\u001b[39m boxcox_transform(Y_train, best_lam)\n",
      "Cell \u001b[1;32mIn[22], line 6\u001b[0m, in \u001b[0;36mboxcox_lambda\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (y\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mall()\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# YOUR CODE HERE\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m _, best_lam \u001b[38;5;241m=\u001b[39m \u001b[43mboxcox\u001b[49m(y)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m best_lam\n",
      "\u001b[1;31mNameError\u001b[0m: name 'boxcox' is not defined"
     ]
    }
   ],
   "source": [
    "some_X = (np.arange(35).reshape(7,5) ** 13) % 20\n",
    "some_Y = np.sum(some_X, axis=1)\n",
    "some_pred, some_model = glmnet_bc(some_X, some_Y)\n",
    "assert np.array_equal(some_pred.round(3), np.array([20.012, 42.985, 40.189, 75.252, 20.012, 50.095, 24.32 ]))\n",
    "\n",
    "# Checking against the pre-computed test database\n",
    "test_results = test_case_checker(lambda *args,**kwargs: glmnet_bc(*args,**kwargs)[0], task_id=5)\n",
    "assert test_results['passed'], test_results['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'perform_computation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mperform_computation\u001b[49m:\n\u001b[0;32m      2\u001b[0m     train_and_plot(glmnet_bc)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'perform_computation' is not defined"
     ]
    }
   ],
   "source": [
    "if perform_computation:\n",
    "    train_and_plot(glmnet_bc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Task 6</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function `glmnet_ridge` that fits a Ridge-regression model from the glmnet library, and takes the following arguments as input:\n",
    "\n",
    "1. `X_train`: A numpy array of the shape `(N,d)` where `N` is the number of training data points, and `d` is the data dimension. Do not assume anything about `N` or `d` other than being a positive integer.\n",
    "2. `Y_train`: A numpy array of the shape `(N,)` where `N` is the number of training data points.\n",
    "3. `X_test`: A numpy array of the shape `(N_test,d)` where `N_test` is the number of testing data points, and `d` is the data dimension.\n",
    "\n",
    "Your model should train on the training features and labels, and then predict on the test data. Your model should return the following two items:\n",
    "\n",
    "1. `fitted_Y_test`: The predicted values on the test data as a numpy array with a shape of `(N_test,)` where `N_test` is the number of testing data points.\n",
    "\n",
    "2. `glmnet_model`: The glmnet library's returned model stored as a python dictionary.\n",
    "\n",
    "**Important Notes**:\n",
    "1. **Do not** play with the default options unless you're instructed to.\n",
    "2. You may find this glmnet documentation helpful: https://github.com/bbalasub1/glmnet_python/blob/master/test/glmnet_examples.ipynb\n",
    "  * You may find it useful to read about the gaussian family in the first section, cross-validation, the functions `cvglmnet` and `cvglmnetPredict`, and their arguments.\n",
    "3. You **should** perform **cross-validation** for this task.\n",
    "4. Use **10-folds** for cross-validation.\n",
    "5. Ask glmnet to search over **100** different values of the regularization coefficient.\n",
    "6. Use the **Mean Squared Error** as a metric for cross-validation.\n",
    "7. For **prediction**, use the **regularization coefficient** that produces the **minimum cross-validation MSE**.\n",
    "7. You may need to choose the proper `family` variable when you're training the model.\n",
    "8. You may need to choose the proper `ptype` variable when you're predicting on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2ddd03c3ccba99ab173a63d3912915ef",
     "grade": false,
     "grade_id": "cell-eb4986f258867396",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def glmnet_ridge(X_train, Y_train, X_test=None):\n",
    "    \n",
    "    if X_test is None:\n",
    "        X_test = X_train.copy().astype(np.float64)\n",
    "    # Creating Scratch Variables For glmnet Consumption\n",
    "    X_train = X_train.copy().astype(np.float64)\n",
    "    Y_train = Y_train.copy().astype(np.float64)\n",
    "    \n",
    "    # YOUR CODE HERE    \n",
    "    glmnet_model = cvglmnet(\n",
    "        x=X_train,\n",
    "        y=Y_train,\n",
    "        family=\"gaussian\",\n",
    "        nfolds=10,\n",
    "        nlambda=100,\n",
    "        ptype=\"mse\"\n",
    "    )\n",
    "    \n",
    "    lambda_min = glmnet_model['lambda_min']\n",
    "    \n",
    "    fitted_Y_test = cvglmnetPredict(\n",
    "        glmnet_model,\n",
    "        newx=X_test,\n",
    "        s=lambda_min,\n",
    "        ptype=\"link\"\n",
    "    ).flatten()\n",
    "    \n",
    "    glmnet_model = dict(glmnet_model)\n",
    "    \n",
    "    assert fitted_Y_test.shape == (X_test.shape[0],), 'fitted_Y should not be two dimensional (hint: reshaping may be helpful)'\n",
    "    assert isinstance(glmnet_model, dict)\n",
    "    return fitted_Y_test, glmnet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6db6d730c4d9bd621e840bbb2f726f25",
     "grade": true,
     "grade_id": "cell-a068d28a595d2355",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cvglmnet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m some_X \u001b[38;5;241m=\u001b[39m (np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m350\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m70\u001b[39m,\u001b[38;5;241m5\u001b[39m) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m13\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[0;32m      2\u001b[0m some_Y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(some_X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m some_pred, some_model \u001b[38;5;241m=\u001b[39m \u001b[43mglmnet_ridge\u001b[49m\u001b[43m(\u001b[49m\u001b[43msome_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msome_Y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(some_pred\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m3\u001b[39m)[:\u001b[38;5;241m5\u001b[39m], np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m21.206\u001b[39m, \u001b[38;5;241m45.052\u001b[39m, \u001b[38;5;241m40.206\u001b[39m, \u001b[38;5;241m73.639\u001b[39m, \u001b[38;5;241m21.206\u001b[39m]))\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Checking against the pre-computed test database\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[31], line 10\u001b[0m, in \u001b[0;36mglmnet_ridge\u001b[1;34m(X_train, Y_train, X_test)\u001b[0m\n\u001b[0;32m      7\u001b[0m Y_train \u001b[38;5;241m=\u001b[39m Y_train\u001b[38;5;241m.\u001b[39mcopy()\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# YOUR CODE HERE    \u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m glmnet_model \u001b[38;5;241m=\u001b[39m \u001b[43mcvglmnet\u001b[49m(\n\u001b[0;32m     11\u001b[0m     x\u001b[38;5;241m=\u001b[39mX_train,\n\u001b[0;32m     12\u001b[0m     y\u001b[38;5;241m=\u001b[39mY_train,\n\u001b[0;32m     13\u001b[0m     family\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgaussian\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     14\u001b[0m     nfolds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m     15\u001b[0m     nlambda\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[0;32m     16\u001b[0m     ptype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     17\u001b[0m )\n\u001b[0;32m     19\u001b[0m lambda_min \u001b[38;5;241m=\u001b[39m glmnet_model[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlambda_min\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     21\u001b[0m fitted_Y_test \u001b[38;5;241m=\u001b[39m cvglmnetPredict(\n\u001b[0;32m     22\u001b[0m     glmnet_model,\n\u001b[0;32m     23\u001b[0m     newx\u001b[38;5;241m=\u001b[39mX_test,\n\u001b[0;32m     24\u001b[0m     s\u001b[38;5;241m=\u001b[39mlambda_min,\n\u001b[0;32m     25\u001b[0m     ptype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlink\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     26\u001b[0m )\u001b[38;5;241m.\u001b[39mflatten()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cvglmnet' is not defined"
     ]
    }
   ],
   "source": [
    "some_X = (np.arange(350).reshape(70,5) ** 13) % 20\n",
    "some_Y = np.sum(some_X, axis=1)\n",
    "some_pred, some_model = glmnet_ridge(some_X, some_Y)\n",
    "assert np.array_equal(some_pred.round(3)[:5], np.array([21.206, 45.052, 40.206, 73.639, 21.206]))\n",
    "\n",
    "# Checking against the pre-computed test database\n",
    "test_results = test_case_checker(lambda *args,**kwargs: glmnet_ridge(*args,**kwargs)[0], task_id=6)\n",
    "assert test_results['passed'], test_results['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'perform_computation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mperform_computation\u001b[49m:\n\u001b[0;32m      2\u001b[0m     train_and_plot(glmnet_ridge)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'perform_computation' is not defined"
     ]
    }
   ],
   "source": [
    "if perform_computation:\n",
    "    train_and_plot(glmnet_ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Lasso Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Task 7</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function `glmnet_lasso` that fits a Lasso-regression model from the glmnet library, and takes the following arguments as input:\n",
    "\n",
    "1. `X_train`: A numpy array of the shape `(N,d)` where `N` is the number of training data points, and `d` is the data dimension. Do not assume anything about `N` or `d` other than being a positive integer.\n",
    "2. `Y_train`: A numpy array of the shape `(N,)` where `N` is the number of training data points.\n",
    "3. `X_test`: A numpy array of the shape `(N_test,d)` where `N_test` is the number of testing data points, and `d` is the data dimension.\n",
    "\n",
    "Your model should train on the training features and labels, and then predict on the test data. Your model should return the following two items:\n",
    "\n",
    "1. `fitted_Y_test`: The predicted values on the test data as a numpy array with a shape of `(N_test,)` where `N_test` is the number of testing data points.\n",
    "\n",
    "2. `glmnet_model`: The glmnet library's returned model stored as a python dictionary.\n",
    "\n",
    "**Important Notes**:\n",
    "1. **Do not** play with the default options unless you're instructed to.\n",
    "2. You may find this glmnet documentation helpful: https://github.com/bbalasub1/glmnet_python/blob/master/test/glmnet_examples.ipynb\n",
    "  * You may find it useful to read about the gaussian family in the first section, cross-validation, the functions `cvglmnet` and `cvglmnetPredict`, and their arguments (specially the alpha parameter for `cvglmnet`).\n",
    "3. You **should** perform **cross-validation** for this task.\n",
    "4. Use **10-folds** for cross-validation.\n",
    "5. Ask glmnet to search over **100** different values of the regularization coefficient.\n",
    "6. Use the **Mean Squared Error** as a metric for cross-validation.\n",
    "7. For **prediction**, use the **regularization coefficient** that produces the **minimum cross-validation MSE**.\n",
    "7. You may need to choose the proper `family` variable when you're training the model.\n",
    "8. You may need to choose the proper `ptype` variable when you're predicting on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2bd0b44c3cfb8e4357f3b4c75e15bc7d",
     "grade": false,
     "grade_id": "cell-5c462a62425bb5e2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def glmnet_lasso(X_train, Y_train, X_test=None):\n",
    "    \n",
    "    if X_test is None:\n",
    "        X_test = X_train.copy().astype(np.float64)\n",
    "    # Creating Scratch Variables For glmnet Consumption\n",
    "    X_train = X_train.copy().astype(np.float64)\n",
    "    Y_train = Y_train.copy().astype(np.float64)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    glmnet_model = cvglmnet(\n",
    "        x=X_train,\n",
    "        y=Y_train,\n",
    "        family=\"gaussian\",\n",
    "        alpha=1.0, \n",
    "        nfolds=10,\n",
    "        nlambda=100,\n",
    "        ptype=\"mse\"\n",
    "    )\n",
    "    \n",
    "    lambda_min = glmnet_model['lambda_min']\n",
    "    \n",
    "    fitted_Y_test = cvglmnetPredict(\n",
    "        glmnet_model,\n",
    "        newx=X_test,\n",
    "        s=lambda_min,\n",
    "        ptype=\"link\"\n",
    "    ).flatten()  \n",
    "\n",
    "    glmnet_model = dict(glmnet_model)\n",
    "\n",
    "    \n",
    "    assert fitted_Y_test.shape == (X_test.shape[0],), 'fitted_Y should not be two dimensional (hint: reshaping may be helpful)'\n",
    "    assert isinstance(glmnet_model, dict)\n",
    "    return fitted_Y_test, glmnet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "af308ec314cfccef3facc323cab5cd6e",
     "grade": true,
     "grade_id": "cell-3facdc3840e0c79d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cvglmnet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m some_X \u001b[38;5;241m=\u001b[39m (np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m350\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m70\u001b[39m,\u001b[38;5;241m5\u001b[39m) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m13\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[0;32m      2\u001b[0m some_Y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(some_X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m some_pred, some_model \u001b[38;5;241m=\u001b[39m \u001b[43mglmnet_lasso\u001b[49m\u001b[43m(\u001b[49m\u001b[43msome_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msome_Y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(some_pred\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m3\u001b[39m)[:\u001b[38;5;241m5\u001b[39m], np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m20.716\u001b[39m, \u001b[38;5;241m45.019\u001b[39m, \u001b[38;5;241m40.11\u001b[39m , \u001b[38;5;241m74.153\u001b[39m, \u001b[38;5;241m20.716\u001b[39m]))\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Checking against the pre-computed test database\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[34], line 10\u001b[0m, in \u001b[0;36mglmnet_lasso\u001b[1;34m(X_train, Y_train, X_test)\u001b[0m\n\u001b[0;32m      7\u001b[0m Y_train \u001b[38;5;241m=\u001b[39m Y_train\u001b[38;5;241m.\u001b[39mcopy()\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# YOUR CODE HERE\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m glmnet_model \u001b[38;5;241m=\u001b[39m \u001b[43mcvglmnet\u001b[49m(\n\u001b[0;32m     11\u001b[0m     x\u001b[38;5;241m=\u001b[39mX_train,\n\u001b[0;32m     12\u001b[0m     y\u001b[38;5;241m=\u001b[39mY_train,\n\u001b[0;32m     13\u001b[0m     family\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgaussian\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     14\u001b[0m     alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, \n\u001b[0;32m     15\u001b[0m     nfolds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m     16\u001b[0m     nlambda\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[0;32m     17\u001b[0m     ptype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     18\u001b[0m )\n\u001b[0;32m     20\u001b[0m lambda_min \u001b[38;5;241m=\u001b[39m glmnet_model[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlambda_min\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     22\u001b[0m fitted_Y_test \u001b[38;5;241m=\u001b[39m cvglmnetPredict(\n\u001b[0;32m     23\u001b[0m     glmnet_model,\n\u001b[0;32m     24\u001b[0m     newx\u001b[38;5;241m=\u001b[39mX_test,\n\u001b[0;32m     25\u001b[0m     s\u001b[38;5;241m=\u001b[39mlambda_min,\n\u001b[0;32m     26\u001b[0m     ptype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlink\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     27\u001b[0m )\u001b[38;5;241m.\u001b[39mflatten()  \n",
      "\u001b[1;31mNameError\u001b[0m: name 'cvglmnet' is not defined"
     ]
    }
   ],
   "source": [
    "some_X = (np.arange(350).reshape(70,5) ** 13) % 20\n",
    "some_Y = np.sum(some_X, axis=1)\n",
    "some_pred, some_model = glmnet_lasso(some_X, some_Y)\n",
    "assert np.array_equal(some_pred.round(3)[:5], np.array([20.716, 45.019, 40.11 , 74.153, 20.716]))\n",
    "\n",
    "# Checking against the pre-computed test database\n",
    "test_results = test_case_checker(lambda *args,**kwargs: glmnet_lasso(*args,**kwargs)[0], task_id=7)\n",
    "assert test_results['passed'], test_results['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'perform_computation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mperform_computation\u001b[49m:\n\u001b[0;32m      2\u001b[0m     train_and_plot(glmnet_lasso)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'perform_computation' is not defined"
     ]
    }
   ],
   "source": [
    "if perform_computation:\n",
    "    train_and_plot(glmnet_lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'perform_computation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mperform_computation\u001b[49m:\n\u001b[0;32m      2\u001b[0m     _, lasso_model \u001b[38;5;241m=\u001b[39m glmnet_lasso(X_train_val, lat_train_val, X_train_val)\n\u001b[0;32m      3\u001b[0m     _, ridge_model \u001b[38;5;241m=\u001b[39m glmnet_ridge(X_train_val, lat_train_val, X_train_val)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'perform_computation' is not defined"
     ]
    }
   ],
   "source": [
    "if perform_computation:\n",
    "    _, lasso_model = glmnet_lasso(X_train_val, lat_train_val, X_train_val)\n",
    "    _, ridge_model = glmnet_ridge(X_train_val, lat_train_val, X_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if perform_computation:\n",
    "    f = plt.figure(figsize=(9,4), dpi=120)\n",
    "    f.add_subplot(1,2,1)\n",
    "    cvglmnetPlot(lasso_model)\n",
    "    plt.gca().set_title('Lasso-Regression Model')\n",
    "    f.add_subplot(1,2,2)\n",
    "    cvglmnetPlot(ridge_model)\n",
    "    _ = plt.gca().set_title('Ridge-Regression Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if perform_computation:\n",
    "    lasso_nz_coefs = np.sum(cvglmnetCoef(lasso_model, s = 'lambda_min') != 0)\n",
    "    ridge_nz_coefs = np.sum(cvglmnetCoef(ridge_model, s = 'lambda_min') != 0)\n",
    "    print(f'A Total of {lasso_nz_coefs} Lasso-Regression coefficients were non-zero.')\n",
    "    print(f'A Total of {ridge_nz_coefs} Ridge-Regression coefficients were non-zero.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.8 Elastic-net Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Task 8</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function `glmnet_elastic` that fits an elastic-net model from the glmnet library, and takes the following arguments as input:\n",
    "\n",
    "1. `X_train`: A numpy array of the shape `(N,d)` where `N` is the number of training data points, and `d` is the data dimension. Do not assume anything about `N` or `d` other than being a positive integer.\n",
    "2. `Y_train`: A numpy array of the shape `(N,)` where `N` is the number of training data points.\n",
    "3. `X_test`: A numpy array of the shape `(N_test,d)` where `N_test` is the number of testing data points, and `d` is the data dimension.\n",
    "4. `alpha`: The elastic-net regularization parameter $\\alpha$.\n",
    "\n",
    "Your model should train on the training features and labels, and then predict on the test data. Your model should return the following two items:\n",
    "\n",
    "1. `fitted_Y_test`: The predicted values on the test data as a numpy array with a shape of `(N_test,)` where `N_test` is the number of testing data points.\n",
    "\n",
    "2. `glmnet_model`: The glmnet library's returned model stored as a python dictionary.\n",
    "\n",
    "**Important Notes**:\n",
    "1. **Do not** play with the default options unless you're instructed to.\n",
    "2. You may find this glmnet documentation helpful: https://github.com/bbalasub1/glmnet_python/blob/master/test/glmnet_examples.ipynb\n",
    "  * You may find it useful to read about the gaussian family in the first section, cross-validation, the functions `cvglmnet` and `cvglmnetPredict`, and their arguments (specially the alpha parameter for `cvglmnet`).\n",
    "3. You **should** perform **cross-validation** for this task.\n",
    "4. Use **10-folds** for cross-validation.\n",
    "5. Ask glmnet to search over **100** different values of the regularization coefficient.\n",
    "6. Use the **Mean Squared Error** as a metric for cross-validation.\n",
    "7. For **prediction**, use the **regularization coefficient** that produces the **minimum cross-validation MSE**.\n",
    "7. You may need to choose the proper `family` variable when you're training the model.\n",
    "8. You may need to choose the proper `ptype` variable when you're predicting on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cf8936ea8f98e80ffe52a775ad672e63",
     "grade": false,
     "grade_id": "cell-6b524abfee9cceff",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def glmnet_elastic(X_train, Y_train, X_test=None, alpha=1):\n",
    "    \n",
    "    if X_test is None:\n",
    "        X_test = X_train.copy().astype(np.float64)\n",
    "    # Creating Scratch Variables For glmnet consumption\n",
    "    X_train = X_train.copy().astype(np.float64)\n",
    "    Y_train = Y_train.copy().astype(np.float64)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    glmnet_model = cvglmnet(\n",
    "        x=X_train,\n",
    "        y=Y_train,\n",
    "        family=\"gaussian\",\n",
    "        alpha=alpha, \n",
    "        nfolds=10,\n",
    "        nlambda=100,\n",
    "        ptype=\"mse\"\n",
    "    )\n",
    "    \n",
    "    lambda_min = glmnet_model['lambda_min']\n",
    "    \n",
    "    fitted_Y_test = cvglmnetPredict(\n",
    "        glmnet_model,\n",
    "        newx=X_test,\n",
    "        s=lambda_min,\n",
    "        ptype=\"link\"\n",
    "    ).flatten()  \n",
    "\n",
    "    glmnet_model = dict(glmnet_model)\n",
    "    \n",
    "    assert fitted_Y_test.shape == (X_test.shape[0],), 'fitted_Y should not be two dimensional (hint: reshaping may be helpful)'\n",
    "    assert isinstance(glmnet_model, dict)\n",
    "    return fitted_Y_test, glmnet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "235023895f90f039a114a367c59cb336",
     "grade": true,
     "grade_id": "cell-8aa0f24d2cbfb3dc",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cvglmnet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m some_X \u001b[38;5;241m=\u001b[39m (np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m350\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m70\u001b[39m,\u001b[38;5;241m5\u001b[39m) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m13\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[0;32m      2\u001b[0m some_Y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(some_X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m some_pred, some_model \u001b[38;5;241m=\u001b[39m \u001b[43mglmnet_elastic\u001b[49m\u001b[43m(\u001b[49m\u001b[43msome_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msome_Y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(some_pred\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m3\u001b[39m)[:\u001b[38;5;241m5\u001b[39m], np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m20.77\u001b[39m , \u001b[38;5;241m45.028\u001b[39m, \u001b[38;5;241m40.125\u001b[39m, \u001b[38;5;241m74.112\u001b[39m, \u001b[38;5;241m20.77\u001b[39m ]))\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Checking against the pre-computed test database\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[38], line 10\u001b[0m, in \u001b[0;36mglmnet_elastic\u001b[1;34m(X_train, Y_train, X_test, alpha)\u001b[0m\n\u001b[0;32m      7\u001b[0m Y_train \u001b[38;5;241m=\u001b[39m Y_train\u001b[38;5;241m.\u001b[39mcopy()\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# YOUR CODE HERE\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m glmnet_model \u001b[38;5;241m=\u001b[39m \u001b[43mcvglmnet\u001b[49m(\n\u001b[0;32m     11\u001b[0m     x\u001b[38;5;241m=\u001b[39mX_train,\n\u001b[0;32m     12\u001b[0m     y\u001b[38;5;241m=\u001b[39mY_train,\n\u001b[0;32m     13\u001b[0m     family\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgaussian\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     14\u001b[0m     alpha\u001b[38;5;241m=\u001b[39malpha, \n\u001b[0;32m     15\u001b[0m     nfolds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m     16\u001b[0m     nlambda\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[0;32m     17\u001b[0m     ptype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     18\u001b[0m )\n\u001b[0;32m     20\u001b[0m lambda_min \u001b[38;5;241m=\u001b[39m glmnet_model[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlambda_min\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     22\u001b[0m fitted_Y_test \u001b[38;5;241m=\u001b[39m cvglmnetPredict(\n\u001b[0;32m     23\u001b[0m     glmnet_model,\n\u001b[0;32m     24\u001b[0m     newx\u001b[38;5;241m=\u001b[39mX_test,\n\u001b[0;32m     25\u001b[0m     s\u001b[38;5;241m=\u001b[39mlambda_min,\n\u001b[0;32m     26\u001b[0m     ptype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlink\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     27\u001b[0m )\u001b[38;5;241m.\u001b[39mflatten()  \n",
      "\u001b[1;31mNameError\u001b[0m: name 'cvglmnet' is not defined"
     ]
    }
   ],
   "source": [
    "some_X = (np.arange(350).reshape(70,5) ** 13) % 20\n",
    "some_Y = np.sum(some_X, axis=1)\n",
    "some_pred, some_model = glmnet_elastic(some_X, some_Y, alpha=0.3)\n",
    "assert np.array_equal(some_pred.round(3)[:5], np.array([20.77 , 45.028, 40.125, 74.112, 20.77 ]))\n",
    "\n",
    "# Checking against the pre-computed test database\n",
    "test_results = test_case_checker(lambda *args,**kwargs: glmnet_elastic(*args,**kwargs)[0], task_id=8)\n",
    "assert test_results['passed'], test_results['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'perform_computation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mperform_computation\u001b[49m:\n\u001b[0;32m      2\u001b[0m     alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.25\u001b[39m\n\u001b[0;32m      3\u001b[0m     train_and_plot(\u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: glmnet_elastic(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, alpha\u001b[38;5;241m=\u001b[39malpha))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'perform_computation' is not defined"
     ]
    }
   ],
   "source": [
    "if perform_computation:\n",
    "    alpha = 0.25\n",
    "    train_and_plot(lambda *args, **kwargs: glmnet_elastic(*args, **kwargs, alpha=alpha))\n",
    "    _ = plt.gcf().suptitle(f'alpha = {alpha}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if perform_computation:\n",
    "    alpha = 0.5\n",
    "    train_and_plot(lambda *args, **kwargs: glmnet_elastic(*args, **kwargs, alpha=alpha))\n",
    "    _ = plt.gcf().suptitle(f'alpha = {alpha}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if perform_computation:\n",
    "    alpha = 0.75\n",
    "    train_and_plot(lambda *args, **kwargs: glmnet_elastic(*args, **kwargs, alpha=alpha))\n",
    "    _ = plt.gcf().suptitle(f'alpha = {alpha}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if perform_computation:\n",
    "    _, alpha1_model = glmnet_elastic(X_train_val, lat_train_val, X_train_val, alpha=0.25)\n",
    "    _, alpha2_model = glmnet_elastic(X_train_val, lat_train_val, X_train_val, alpha=0.5)\n",
    "    _, alpha3_model = glmnet_elastic(X_train_val, lat_train_val, X_train_val, alpha=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if perform_computation:\n",
    "    f = plt.figure(figsize=(9,3), dpi=120)\n",
    "    f.add_subplot(1,3,1)\n",
    "    cvglmnetPlot(alpha1_model)\n",
    "    plt.gca().set_title(f'Elastic Net (Alpha=0.25)')\n",
    "    f.add_subplot(1,3,2)\n",
    "    cvglmnetPlot(alpha2_model)\n",
    "    plt.gca().set_title(f'Elastic Net (Alpha=0.5)')\n",
    "    f.add_subplot(1,3,3)\n",
    "    cvglmnetPlot(alpha3_model)\n",
    "    _ = plt.gca().set_title(f'Elastic Net (Alpha=0.75)')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if perform_computation:\n",
    "    alpha1_nz_coefs = np.sum(cvglmnetCoef(alpha1_model, s = 'lambda_min') != 0)\n",
    "    alpha2_nz_coefs = np.sum(cvglmnetCoef(alpha2_model, s = 'lambda_min') != 0)\n",
    "    alpha3_nz_coefs = np.sum(cvglmnetCoef(alpha3_model, s = 'lambda_min') != 0)\n",
    "\n",
    "    print(f'With an alpha of 0.25, a Total of {alpha1_nz_coefs} elastic-net coefficients were non-zero.')\n",
    "    print(f'With an alpha of 0.50, a Total of {alpha2_nz_coefs} elastic-net coefficients were non-zero.')\n",
    "    print(f'With an alpha of 0.75, a Total of {alpha3_nz_coefs} elastic-net coefficients were non-zero.')\n",
    "\n",
    "    fig,ax = plt.subplots(figsize=(8,5), dpi=100)\n",
    "    ax.plot([0,0.25,0.5,0.75,1], [ridge_nz_coefs, alpha1_nz_coefs, alpha2_nz_coefs, alpha3_nz_coefs, lasso_nz_coefs])\n",
    "    ax.set_xlabel('The Elastic-Net Alpha Parameter')\n",
    "    ax.set_ylabel('The Number of Non-zero Coefficients')\n",
    "    _ = ax.set_title('The Number of Used Features Vs. The Elastic-Net Alpha Parameter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UCI Machine Learning dataset repository hosts a dataset giving whether a Taiwanese credit card user defaults against a variety of features at http://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Input/Output**: This data has 24 columns; the first 23 columns are the features, and the last column is an indicator variable telling whether the next month's payment was defaulted.\n",
    "\n",
    "* **Missing Data**: There is no missing data.\n",
    "\n",
    "* **Final Goal**: We want to **properly** fit a logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('credit/credit.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = df.iloc[:,:-1].values\n",
    "Y_full = df.iloc[:,-1].values\n",
    "X_full.shape, Y_full.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_detector = 'LOF'\n",
    "\n",
    "if outlier_detector == 'LOF':\n",
    "    outlier_clf = LocalOutlierFactor(novelty=False)\n",
    "elif outlier_detector == 'IF':\n",
    "    outlier_clf = IsolationForest(warm_start=True, random_state=12345)\n",
    "elif outlier_detector == 'EE':\n",
    "    outlier_clf = EllipticEnvelope(random_state=12345)\n",
    "else:\n",
    "    outlier_clf = None\n",
    "\n",
    "is_not_outlier = outlier_clf.fit_predict(X_full) if outlier_clf is not None else np.ones_like(lat_full)>0\n",
    "X_useful = X_full[is_not_outlier==1,:]\n",
    "Y_useful = Y_full[is_not_outlier==1]\n",
    "\n",
    "X_useful.shape, Y_useful.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Train-Validation-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_indices, test_indices = train_test_split(np.arange(X_useful.shape[0]), test_size=0.2, random_state=12345)\n",
    "\n",
    "X_train_val = X_useful[train_val_indices, :]\n",
    "Y_train_val = Y_useful[train_val_indices]\n",
    "\n",
    "X_test = X_useful[test_indices, :]\n",
    "Y_test = Y_useful[test_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Elastic Net Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Task 9</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function `glmnet_logistic_elastic` that fits an elastic-net logistic regression model from the glmnet library, and takes the following arguments as input:\n",
    "\n",
    "1. `X_train`: A numpy array of the shape `(N,d)` where `N` is the number of training data points, and `d` is the data dimension. Do not assume anything about `N` or `d` other than being a positive integer.\n",
    "2. `Y_train`: A numpy array of the shape `(N,)` where `N` is the number of training data points.\n",
    "3. `X_test`: A numpy array of the shape `(N_test,d)` where `N_test` is the number of testing data points, and `d` is the data dimension.\n",
    "4. `alpha`: The elastic-net regularization parameter $\\alpha$.\n",
    "\n",
    "Your model should train on the training features and labels, and then predict on the test data. Your model should return the following two items:\n",
    "\n",
    "1. `fitted_Y_test`: The predicted values on the test data as a numpy array with a shape of `(N_test,)` where `N_test` is the number of testing data points. These values should indicate the prediction classes for test data, and should be either 0 or 1.\n",
    "\n",
    "2. `glmnet_model`: The glmnet library's returned model stored as a python dictionary.\n",
    "\n",
    "**Important Notes**:\n",
    "1. **Do not** play with the default options unless you're instructed to.\n",
    "2. You may find this glmnet documentation helpful: https://github.com/bbalasub1/glmnet_python/blob/master/test/glmnet_examples.ipynb\n",
    "  * You may find it useful to read about the logistic family in the last sections.\n",
    "3. You **should** perform **cross-validation** for this task.\n",
    "4. Use **10-folds** for cross-validation.\n",
    "5. Ask glmnet to search over **100** different values of the regularization coefficient.\n",
    "6. Use the **Misclassification Error** as a metric for cross-validation.\n",
    "7. For **prediction**, use the **regularization coefficient** that produces the **minimum cross-validation misclassification**.\n",
    "7. You may need to choose the proper `family` variable when you're training the model.\n",
    "8. You may need to choose the proper `ptype` variable when you're predicting on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f0442e1628d97ac79e50a4583c7267a8",
     "grade": false,
     "grade_id": "cell-116057c7411df8de",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def glmnet_logistic_elastic(X_train, Y_train, X_test=None, alpha=1):\n",
    "    \n",
    "    if X_test is None:\n",
    "        X_test = X_train.copy().astype(np.float64)\n",
    "    # Creating Scratch Variables For glmnet consumption\n",
    "    X_train = X_train.copy().astype(np.float64)\n",
    "    Y_train = Y_train.copy().astype(np.float64)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    glmnet_model = cvglmnet(\n",
    "        x=X_train,\n",
    "        y=Y_train,\n",
    "        family=\"binomial\", \n",
    "        alpha=alpha,  \n",
    "        nfolds=10,\n",
    "        nlambda=100,\n",
    "        ptype=\"class\"  \n",
    "    )\n",
    "    \n",
    "    lambda_min = glmnet_model['lambda_min']\n",
    "    \n",
    "    fitted_Y_test = cvglmnetPredict(\n",
    "        glmnet_model,\n",
    "        newx=X_test,\n",
    "        s=lambda_min,\n",
    "        ptype=\"class\"\n",
    "    ).flatten().astype(int)  \n",
    "\n",
    "    glmnet_model = dict(glmnet_model)\n",
    "    \n",
    "    assert fitted_Y_test.shape == (X_test.shape[0],), 'fitted_Y should not be two dimensional (hint: reshaping may be helpful)'\n",
    "    assert isinstance(glmnet_model, dict)\n",
    "    return fitted_Y_test, glmnet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "96d562473bb512ee1353db6103e839ac",
     "grade": true,
     "grade_id": "cell-07eefe84ea29503c",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cvglmnet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m some_X \u001b[38;5;241m=\u001b[39m (np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m350\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m70\u001b[39m,\u001b[38;5;241m5\u001b[39m) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m13\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[0;32m      2\u001b[0m some_Y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(some_X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m----> 3\u001b[0m some_pred, some_model \u001b[38;5;241m=\u001b[39m \u001b[43mglmnet_logistic_elastic\u001b[49m\u001b[43m(\u001b[49m\u001b[43msome_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msome_Y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(some_pred\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m3\u001b[39m)[:\u001b[38;5;241m5\u001b[39m], np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m1.\u001b[39m, \u001b[38;5;241m0.\u001b[39m]))\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Checking against the pre-computed test database\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[41], line 10\u001b[0m, in \u001b[0;36mglmnet_logistic_elastic\u001b[1;34m(X_train, Y_train, X_test, alpha)\u001b[0m\n\u001b[0;32m      7\u001b[0m Y_train \u001b[38;5;241m=\u001b[39m Y_train\u001b[38;5;241m.\u001b[39mcopy()\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# YOUR CODE HERE\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m glmnet_model \u001b[38;5;241m=\u001b[39m \u001b[43mcvglmnet\u001b[49m(\n\u001b[0;32m     11\u001b[0m     x\u001b[38;5;241m=\u001b[39mX_train,\n\u001b[0;32m     12\u001b[0m     y\u001b[38;5;241m=\u001b[39mY_train,\n\u001b[0;32m     13\u001b[0m     family\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinomial\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m     14\u001b[0m     alpha\u001b[38;5;241m=\u001b[39malpha,  \n\u001b[0;32m     15\u001b[0m     nfolds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m     16\u001b[0m     nlambda\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[0;32m     17\u001b[0m     ptype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m  \n\u001b[0;32m     18\u001b[0m )\n\u001b[0;32m     20\u001b[0m lambda_min \u001b[38;5;241m=\u001b[39m glmnet_model[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlambda_min\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     22\u001b[0m fitted_Y_test \u001b[38;5;241m=\u001b[39m cvglmnetPredict(\n\u001b[0;32m     23\u001b[0m     glmnet_model,\n\u001b[0;32m     24\u001b[0m     newx\u001b[38;5;241m=\u001b[39mX_test,\n\u001b[0;32m     25\u001b[0m     s\u001b[38;5;241m=\u001b[39mlambda_min,\n\u001b[0;32m     26\u001b[0m     ptype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     27\u001b[0m )\u001b[38;5;241m.\u001b[39mflatten()\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)  \n",
      "\u001b[1;31mNameError\u001b[0m: name 'cvglmnet' is not defined"
     ]
    }
   ],
   "source": [
    "some_X = (np.arange(350).reshape(70,5) ** 13) % 20\n",
    "some_Y = np.sum(some_X, axis=1)%2\n",
    "some_pred, some_model = glmnet_logistic_elastic(some_X, some_Y, alpha=0.3)\n",
    "assert np.array_equal(some_pred.round(3)[:5], np.array([0., 0., 0., 1., 0.]))\n",
    "\n",
    "# Checking against the pre-computed test database\n",
    "test_results = test_case_checker(lambda *args,**kwargs: glmnet_logistic_elastic(*args,**kwargs)[0], task_id=9)\n",
    "assert test_results['passed'], test_results['message']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if perform_computation:\n",
    "    _, ridge_model = glmnet_logistic_elastic(X_train_val, Y_train_val, X_train_val, alpha=0.00)\n",
    "    _, alpha1_model = glmnet_logistic_elastic(X_train_val, Y_train_val, X_train_val, alpha=0.25)\n",
    "    _, alpha2_model = glmnet_logistic_elastic(X_train_val, Y_train_val, X_train_val, alpha=0.50)\n",
    "    _, alpha3_model = glmnet_logistic_elastic(X_train_val, Y_train_val, X_train_val, alpha=0.75)\n",
    "    _, lasso_model = glmnet_logistic_elastic(X_train_val, Y_train_val, X_train_val, alpha=1.00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if perform_computation:\n",
    "    f = plt.figure(figsize=(9,4), dpi=120)\n",
    "    f.add_subplot(1,2,1)\n",
    "    cvglmnetPlot(lasso_model)\n",
    "    plt.gca().set_title('Lasso-Regression Model')\n",
    "    f.add_subplot(1,2,2)\n",
    "    cvglmnetPlot(ridge_model)\n",
    "    _ = plt.gca().set_title('Ridge-Regression Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if perform_computation:\n",
    "    f = plt.figure(figsize=(9,3), dpi=120)\n",
    "    f.add_subplot(1,3,1)\n",
    "    cvglmnetPlot(alpha1_model)\n",
    "    plt.gca().set_title(f'Elastic Net (Alpha=0.25)')\n",
    "    f.add_subplot(1,3,2)\n",
    "    cvglmnetPlot(alpha2_model)\n",
    "    plt.gca().set_title(f'Elastic Net (Alpha=0.5)')\n",
    "    f.add_subplot(1,3,3)\n",
    "    cvglmnetPlot(alpha3_model)\n",
    "    _ = plt.gca().set_title(f'Elastic Net (Alpha=0.75)')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if perform_computation:\n",
    "    lasso_nz_coefs = np.sum(cvglmnetCoef(lasso_model, s = 'lambda_min') != 0)\n",
    "    ridge_nz_coefs = np.sum(cvglmnetCoef(ridge_model, s = 'lambda_min') != 0)\n",
    "    alpha1_nz_coefs = np.sum(cvglmnetCoef(alpha1_model, s = 'lambda_min') != 0)\n",
    "    alpha2_nz_coefs = np.sum(cvglmnetCoef(alpha2_model, s = 'lambda_min') != 0)\n",
    "    alpha3_nz_coefs = np.sum(cvglmnetCoef(alpha3_model, s = 'lambda_min') != 0)\n",
    "\n",
    "    print(f'A Total of {ridge_nz_coefs} Ridge-Regression coefficients were non-zero.')\n",
    "    print(f'With an alpha of 0.25, a Total of {alpha1_nz_coefs} elastic-net coefficients were non-zero.')\n",
    "    print(f'With an alpha of 0.50, a Total of {alpha2_nz_coefs} elastic-net coefficients were non-zero.')\n",
    "    print(f'With an alpha of 0.75, a Total of {alpha3_nz_coefs} elastic-net coefficients were non-zero.')\n",
    "    print(f'A Total of {lasso_nz_coefs} Lasso-Regression coefficients were non-zero.')\n",
    "\n",
    "    fig,ax = plt.subplots(figsize=(8,5), dpi=100)\n",
    "    ax.plot([0,0.25,0.5,0.75,1], [ridge_nz_coefs, alpha1_nz_coefs, alpha2_nz_coefs, alpha3_nz_coefs, lasso_nz_coefs])\n",
    "    ax.set_xlabel('The Elastic-Net Alpha Parameter')\n",
    "    ax.set_ylabel('The Number of Non-zero Coefficients')\n",
    "    _ = ax.set_title('The Number of Used Features Vs. The Elastic-Net Alpha Parameter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
